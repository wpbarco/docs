---
title: Harness Capabilities
description: Description of what capabilities come in the deepagents Agent Harness
---

We think of `deepagents` as an "agent harness".
It is the same core tool calling loop as other agent frameworks, but with built-in tools and capabilities.
Here we list out the components that make up this agent harness

## Filesystem Access

Provides 6 tools for file system operations, making files first-class citizens in the agent's environment.

**Tools provided:**
- `ls` - List files in a directory with metadata (size, modified time)
- `read_file` - Read file contents with line numbers, supports offset/limit for large files
- `write_file` - Create new files
- `edit_file` - Perform exact string replacements in files (with global replace mode)
- `glob` - Find files matching patterns (e.g., `**/*.py`)
- `grep` - Search file contents with multiple output modes (files only, content with context, or counts)

---

## Large Tool Result Eviction

Automatically dumps large tool results to the filesystem when they exceed a token threshold, preventing context window saturation.

**How it works:**
- Monitors tool call results for size (default threshold: 20,000 tokens)
- When exceeded, writes the result to a file instead
- Replaces the tool result with a concise reference to the file
- Agent can later read the file if needed

---
## Pluggable Storage Backends

Abstracts filesystem operations behind a protocol, allowing different storage strategies for different use cases.

**Available backends:**

1. **StateBackend** - Ephemeral in-memory storage
   - Files live in the agent's state (checkpointed with conversation)
   - Persists within a thread but not across threads
   - Useful for temporary working files

2. **FilesystemBackend** - Real filesystem access
   - Read/write from actual disk
   - Supports virtual mode (sandboxed to a root directory)
   - Integrates with system tools (ripgrep for grep)
   - Security features: path validation, size limits, symlink prevention

3. **StoreBackend** - Persistent cross-conversation storage
   - Uses LangGraph's BaseStore for durability
   - Namespaced per assistant_id
   - Files persist across conversations
   - Useful for long-term memory or knowledge bases

4. **CompositeBackend** - Route different paths to different backends
   - Example: `/` → StateBackend, `/memories/` → StoreBackend
   - Longest-prefix matching for routing
   - Enables hybrid storage strategies
   
---
## Task Delegation (Subagents)

Allows the main agent to spawn ephemeral "subagents" for isolated multi-step tasks.

**Why it's useful:**
- **Context isolation** - Subagent's work doesn't clutter main agent's context
- **Parallel execution** - Multiple subagents can run concurrently
- **Specialization** - Subagents can have different tools/configurations
- **Token efficiency** - Large subtask context is compressed into a single result

**How it works:**
- Main agent has a `task` tool
- When invoked, creates a fresh agent instance with its own context
- Subagent executes autonomously until completion
- Returns a single final report to the main agent
- Subagents are stateless (can't send multiple messages back)

**Default subagent:**
- "general-purpose" subagent automatically available
- Has filesystem tools by default
- Can be customized with additional tools/middleware

**Custom subagents:**
- Define specialized subagents with specific tools
- Example: code-reviewer, web-researcher, test-runner
- Configure via `subagents` parameter

---

## Conversation History Summarization

Automatically compresses old conversation history when token usage becomes excessive.

**Configuration:**
- Triggers at 170,000 tokens
- Keeps the most recent 6 messages intact
- Older messages are summarized by the model

**Why it's useful:**
- Enables very long conversations without hitting context limits
- Preserves recent context while compressing ancient history
- Transparent to the agent (appears as a special system message)

---

## Dangling Tool Call Repair

Fixes message history when tool calls are interrupted or cancelled before receiving results.

**The problem:**
- Agent requests tool call: "Please run X"
- Tool call is interrupted (user cancels, error, etc.)
- Agent sees tool_call in AIMessage but no corresponding ToolMessage
- This creates an invalid message sequence

**The solution:**
- Detects AIMessages with tool_calls that have no results
- Creates synthetic ToolMessage responses indicating the call was cancelled
- Repairs the message history before agent execution

**Why it's useful:**
- Prevents agent confusion from incomplete message chains
- Gracefully handles interruptions and errors
- Maintains conversation coherence

---

## Todo List Tracking

Provides a `write_todos` tool that agents can use to maintain a structured task list.

**Features:**
- Track multiple tasks with statuses (pending, in_progress, completed)
- Persisted in agent state
- Helps agent organize complex multi-step work
- Useful for long-running tasks and planning

---

## Human-in-the-Loop

Pauses agent execution at specified tool calls to allow human approval/modification.

**Configuration:**
- Map tool names to interrupt configurations
- Example: `{"edit_file": True}` - pause before every edit
- Can provide approval messages or modify tool inputs

**Why it's useful:**
- Safety gates for destructive operations
- User verification before expensive API calls
- Interactive debugging and guidance

---

## Prompt Caching (Anthropic)

Enables Anthropic's prompt caching feature to reduce redundant token processing.

**How it works:**
- Caches portions of the prompt that repeat across turns
- Significantly reduces latency and cost for long system prompts
- Automatically skips for non-Anthropic models

**Why it's useful:**
- System prompts (especially with filesystem docs) can be 5k+ tokens
- These repeat every turn without caching
- Caching provides ~10x speedup and cost reduction
