---
title: Customizing Deep Agents
description: Learn how to customize deep agents with system prompts, tools, subagents, and more
---

## System Prompt

Deep agents come with a built-in system prompt that is heavily based on and inspired by Claude Code's system prompt. The default system prompt contains detailed instructions for how to use the built-in planning tool, file system tools, and sub agents.

Each deep agent tailored to a use case should include a custom system prompt specific to that use case as well!

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

# Search tool to use to do research
def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.

You have access to an internet search tool.

## `internet_search`
Use this to run an internet search for a given query. You can specify the number of results, the topic, and whether raw content should be included.
"""

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    system_prompt=research_instructions,
    tools=[internet_search]
)
```

## Tools

Just like tool-calling agents, a deep agent gets a set of top level tools that it has access to.

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

# Search tool to use to do research
def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[internet_search]
)
```

In addition to any tools that you provide, deep agents also get access to a number of default tools. These are:

- **write_todos** - Update the agent's to-do list
- **ls** - List all files in the agent's filesystem
- **read_file** - Read a file from the agent's filesystem
- **write_file** - Write a new file in the agent's filesystem
- **edit_file** - Edit an existing file in the agent's filesystem
- **task** - Spawn a subagent to handle a specific task

You can learn more about these tools in the [PlanningMiddleware](/oss/deepagents/middleware#planning-middleware), [FilesystemMiddleware](/oss/deepagents/middleware#filesystem-middleware), and [SubAgentMiddleware](/oss/deepagents/middleware#subagent-middleware) sections!

## Subagents

A main feature of Deep Agents is their ability to spawn subagents. You can specify custom subagents that your agent can hand off work to in the `subagents` parameter. Sub agents are useful for [context quarantine](https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html#context-quarantine) (to help not pollute the overall context of the main agent) as well as custom instructions.

```python
from deepagents import create_deep_agent

research_subagent = {
    "name": "research-agent",
    "description": "Used to research more in depth questions",
    "system_prompt": sub_research_prompt,
    "tools": [internet_search],
    "model": "openai:gpt-4o",  # Optional override, defaults to main agent model
    "middleware": []  # Optional list of additional middleware to provide to the subagent
}
subagents = [research_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    subagents=subagents
)
```

A subagent is defined with a **name**, **description**, **system prompt**, and **tools**. You can also provide a subagent with a custom **model**, or with additional **middleware**. This can be particularly useful when you want to give the subagent an additional state key to share with the main agent.

For more complex use cases, you can also provide your own pre-built LangGraph graph as a subagent.

```python
from deepagents import create_deep_agent, CompiledSubAgent
from langchain.agents import create_agent
from langgraph.pregel.remote import RemoteGraph

# Create a custom agent graph
custom_graph = create_agent(
    model=your_model,
    tools=specialized_tools,
    prompt="You are a specialized agent for data analysis..."
)

# Use it as a custom subagent
custom_subagent = CompiledSubAgent(
    name="data-analyzer",
    description="Specialized agent for complex data analysis tasks",
    runnable=custom_graph
)

subagents = [custom_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[internet_search],
    system_prompt=research_instructions,
    subagents=subagents
)
```

In addition to any user defined subagents, deep agents have access to a `general-purpose` subagent at all times - this is a subagent with the same instructions as the main agent and all the tools that is has access to. The primary purpose of the `general-purpose` subagent is to context isolation. The main agent can always delegate a complex task to this subagent, and get a concise answer back without any bloat from intermediate tool calls.

## Human-in-the-Loop

A common reality for agents is that some tool operations may be sensitive and require human approval before execution. Deep Agents supports human-in-the-loop workflows through LangGraph's interrupt capabilities. You can configure which tools require approval using a checkpointer.

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent
from langgraph.checkpoint.memory import MemorySaver

@tool
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

checkpointer = MemorySaver()

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[get_weather],
    checkpointer=checkpointer
)

# To interrupt before specific tools, configure interrupts in your graph
# See LangGraph documentation for more details on interrupt configurations
```

## Long-term Memory

Deep agents come with a local filesystem to offload memory to. This filesystem is stored in state, and is therefore transient to a single thread.

You can extend deep agents with long-term memory by providing a `Store` and setting `use_longterm_memory=True`.

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent
from langgraph.store.memory import InMemoryStore

@tool
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

store = InMemoryStore()  # Or any other Store object
agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[get_weather],
    store=store,
    use_longterm_memory=True
)
```

Extending a deep agent with long-term memory allows all of the filesystem tools to access and store files in the long-term memory store. Specifically, any files that start with the path `/memories/` are saved in long-term memory. This store can be accessed **across** different threads.

An example usage of long-term memory is to store instructions for the agent. An agent can be prompted to call its `edit_file` tool to update its own instructions file in `/memories/instructions.txt` any time a user provides some feedback. Overtime, the instructions.txt file in long-term memory accumulates more and more of the users preferences, so that the agent can get better at its job.

## Additional Middleware

`create_deep_agent` is implemented with middleware that can be customized. You can provide additional middleware to extend functionality, add tools, or implement custom hooks. Learn more about middleware in the [middleware section](/oss/deepagents/middleware).

```python
from deepagents import create_deep_agent
from langchain.tools import tool
from langchain.agents.middleware import AgentState, AgentMiddleware

@tool
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

@tool
def get_temperature(city: str) -> str:
    """Get the temperature in a city."""
    return f"The temperature in {city} is 70 degrees Fahrenheit."

class WeatherMiddleware(AgentMiddleware):
  tools = [get_weather, get_temperature]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[WeatherMiddleware()]
)
```
