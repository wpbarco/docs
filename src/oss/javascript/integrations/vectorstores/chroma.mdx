---
title: Chroma
---

[Chroma](https://docs.trychroma.com/getting-started) is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0.

This guide provides a quick overview for getting started with Chroma [`vector stores`](/oss/integrations/vectorstores). For detailed documentation of all `Chroma` features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_community_vectorstores_chroma.Chroma.html).

<Info>
**Chroma Cloud**

Chroma Cloud powers serverless vector and full-text search. It's extremely fast, cost-effective, scalable and painless. Create a DB and try it out in under 30 seconds with $5 of free credits.

[Get started with Chroma Cloud](https://trychroma.com/signup)

</Info>

## Overview

### Integration details

| Class | Package | [PY support](https://python.langchain.com/docs/integrations/vectorstores/chroma/) | Version |
| :--- | :--- | :---: | :---: |
| [`Chroma`](https://api.js.langchain.com/classes/langchain_community_vectorstores_chroma.Chroma.html) | [`@langchain/community`](https://www.npmjs.com/package/@langchain/community) | âœ… |  ![NPM - Version](https://img.shields.io/npm/v/@langchain/community?style=flat-square&label=%20&) |

## Setup

To use Chroma vector stores, you'll need to install the `@langchain/community` integration package along with the [Chroma JS SDK](https://www.npmjs.com/package/chromadb) as a peer dependency.

This guide will also use [OpenAI embeddings](/oss/integrations/text_embedding/openai), which require you to install the `@langchain/openai` integration package. You can also use [other supported embeddings models](/oss/integrations/text_embedding) if you wish.

<CodeGroup>
```bash npm
npm install @langchain/community @langchain/openai @langchain/core chromadb
```
```bash yarn
yarn add @langchain/community @langchain/openai @langchain/core chromadb
```
```bash pnpm
pnpm add @langchain/community @langchain/openai @langchain/core chromadb
```
</CodeGroup>

If you want to run Chroma locally, you can [run a local Chroma server](https://docs.trychroma.com/docs/cli/run) using the Chroma CLI, which ships with the `chromadb` package:

```
chroma run
```

You can also run a server on Docker, using the official Chroma image:

```
docker pull chromadb/chroma
docker run -p 8000:8000 chromadb/chroma
```

### Credentials

If you are running Chroma locally, you do not need to provide any credentials.

If you are a [Chroma Cloud](https://trychroma.com/signup) user, set your `CHROMA_TENANT`, `CHROMA_DATABASE`, and `CHROMA_API_KEY` environment variables.

The Chroma CLI can set these for you. First, [login](https://docs.trychroma.com/docs/cli/login) via the CLI, and then use the [`connect` command](https://docs.trychroma.com/docs/cli/db):

```
chroma db connect [db_name] --env-file
```

If you are using OpenAI embeddings for this guide, you'll need to set your OpenAI key as well:

```typescript
process.env.OPENAI_API_KEY = "YOUR_API_KEY";
```

If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:

```typescript
// process.env.LANGSMITH_TRACING="true"
// process.env.LANGSMITH_API_KEY="your-api-key"
```

## Instantiation

### Setup your embedding function

First, choose your embedding function. Here we use `OpenAIEmbeddings`:

```python
import { OpenAIEmbeddings } from "@langchain/openai";

const embeddings = new OpenAIEmbeddings({
  model: "text-embedding-3-small",
});
```

### Running Locally

A simple `Chroma` instantiation will connect to a Chroma server running locally on `http://localhost:8000`:

```python
import { Chroma } from "@langchain/community/vectorstores/chroma";

const vectorStore = new Chroma(embeddings, {
  collectionName: "a-test-collection"
});
```

If you are running your Chroma server using a different configuration, you can specify your `host`, `port` and whether to connect using `ssl`:

```python
import { Chroma } from "@langchain/community/vectorstores/chroma";

const vectorStore = new Chroma(embeddings, {
  collectionName: "a-test-collection",
  host: "your-host-address",
  port: 8080
});
```

### Chroma Cloud

To connect to Chroma Cloud, provide your `tenant`, `database`, and `chromaCloudAPIKey`:

```python
import { Chroma } from "@langchain/community/vectorstores/chroma";

const vectorStore = new Chroma(embeddings, {
  collectionName: "a-test-collection",
  chromaCloudAPIKey: process.env.CHROMA_API_KEY,
  clientParams: {
    host: "api.trychroma.com",
    port: 8000,
    ssl: true,
    tenant: process.env.CHROMA_TENANT,
    database: process.env.CHROMA_DATABASE,
  },
});
```

## Manage vector store

### Add items to vector store

```python
import type { Document } from "@langchain/core/documents";

const document1: Document = {
  pageContent: "The powerhouse of the cell is the mitochondria",
  metadata: { source: "https://example.com" }
};

const document2: Document = {
  pageContent: "Buildings are made out of brick",
  metadata: { source: "https://example.com" }
};

const document3: Document = {
  pageContent: "Mitochondria are made out of lipids",
  metadata: { source: "https://example.com" }
};

const document4: Document = {
  pageContent: "The 2024 Olympics are in Paris",
  metadata: { source: "https://example.com" }
}

const documents = [document1, document2, document3, document4];

await vectorStore.addDocuments(documents, { ids: ["1", "2", "3", "4"] });
```

### Delete items from vector store

You can delete documents from Chroma by id as follows:

```python
await vectorStore.delete({ ids: ["4"] });
```

## Query vector store

Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.

### Query directly

Performing a simple similarity search can be done as follows:

```python
const filter = { source: "https://example.com" };

const similaritySearchResults = await vectorStore.similaritySearch("biology", 2, filter);

for (const doc of similaritySearchResults) {
  console.log(`* ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);
}
```

See [this page](https://docs.trychroma.com/guides#filtering-by-metadata) for more on Chroma filter syntax.

If you want to execute a similarity search and receive the corresponding scores you can run:

```python
const similaritySearchWithScoreResults = await vectorStore.similaritySearchWithScore("biology", 2, filter)

for (const [doc, score] of similaritySearchWithScoreResults) {
  console.log(`* [SIM=${score.toFixed(3)}] ${doc.pageContent} [${JSON.stringify(doc.metadata)}]`);
}
```

### Query by turning into retriever

You can also transform the vector store into a [retriever](/oss/langchain/retrieval) for easier usage in your chains.

```python
const retriever = vectorStore.asRetriever({
  // Optional filter
  filter: filter,
  k: 2,
});
await retriever.invoke("biology");
```

### Usage for retrieval-augmented generation

For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:

- [Build a RAG app with LangChain](/oss/langchain/rag).
- [Agentic RAG](/oss/langgraph/agentic-rag)
- [Retrieval docs](/oss/langchain/retrieval)

## API reference

For detailed documentation of all `Chroma` features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_community_vectorstores_chroma.Chroma.html)
