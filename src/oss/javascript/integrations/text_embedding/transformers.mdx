---
title: HuggingFace Transformers
---

The `TransformerEmbeddings` class uses the [Transformers.js](https://huggingface.co/docs/transformers.js/index) package to generate embeddings for a given text.

It runs locally and even works directly in the browser, allowing you to create web apps with built-in embeddings.

## Setup

You'll need to install the [@huggingface/transformers](https://www.npmjs.com/package/@huggingface/transformers) package as a peer dependency:

<Tip>
**Compatibility**

If you are using a version of community older than 0.3.21, install the older `@xenova/transformers` package and
import the embeddings from `"@langchain/community/embeddings/hf_transformers"` below.
</Tip>

```bash npm
npm install @huggingface/transformers
```
<Tip>
See [this section for general instructions on installing LangChain packages](/oss/langchain/install).
</Tip>

```bash npm
npm install @langchain/community @langchain/core
```

## Example

Note that if you're using in a browser context, you'll likely want to put all inference-related code in a web worker to avoid
blocking the main thread.

See [this guide](https://huggingface.co/docs/transformers.js/tutorials/next) and the other resources in the Transformers.js docs for an idea of how to
set up your project.

```typescript
import { HuggingFaceTransformersEmbeddings } from "@langchain/community/embeddings/huggingface_transformers";

const model = new HuggingFaceTransformersEmbeddings({
  model: "Xenova/all-MiniLM-L6-v2",
});

/* Embed queries */
const res = await model.embedQuery(
  "What would be a good company name for a company that makes colorful socks?"
);
console.log({ res });
/* Embed documents */
const documentRes = await model.embedDocuments(["Hello world", "Bye bye"]);
console.log({ documentRes });
```

## Related

- Embedding model [conceptual guide](/oss/integrations/text_embedding)
- Embedding model [how-to guides](/oss/integrations/text_embedding)
