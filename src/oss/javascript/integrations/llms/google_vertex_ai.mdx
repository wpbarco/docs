---
title: Google Vertex AI
---


<Warning>
**You are currently on a page documenting the use of Google Vertex models as text completion models. Many popular models available on Google Vertex are [chat completion models](/oss/langchain/models).**


You may be looking for [this page instead](/oss/integrations/chat/google_vertex_ai/).
</Warning>


[Google Vertex](https://cloud.google.com/vertex-ai) is a service that exposes all foundation models available in Google Cloud, like `gemini-1.5-pro`, `gemini-1.5-flash`, etc.

This will help you get started with VertexAI completion models (LLMs) using LangChain. For detailed documentation on `VertexAI` features and configuration options, please refer to the [API reference](https://api.js.langchain.com/classes/langchain_google_vertexai.VertexAI.html).

## Overview

### Integration details

| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/llms/google_vertex_ai_palm) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [VertexAI](https://api.js.langchain.com/classes/langchain_google_vertexai.VertexAI.html) | [`@langchain/google-vertexai`](https://www.npmjs.com/package/@langchain/google-vertexai) | ❌ | ✅ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/google-vertexai?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/google-vertexai?style=flat-square&label=%20&) |

## Setup

LangChain.js supports two different authentication methods based on whether
you're running in a Node.js environment or a web environment.

To access VertexAI models you'll need to create a Google Cloud Platform (GCP) account, get an API key, and install the `@langchain/google-vertexai` integration package.

### Credentials

#### Node.js

You should make sure the Vertex AI API is
enabled for the relevant project and that you've authenticated to
Google Cloud using one of these methods:

- You are logged into an account (using `gcloud auth application-default login`)
  permitted to that project.
- You are running on a machine using a service account that is permitted
  to the project.
- You have downloaded the credentials for a service account that is permitted
  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment
  variable to the path of this file.
  **or**
- You set the `GOOGLE_API_KEY` environment variable to the API key for the project.

#### Web

To call Vertex AI models in web environments (like Edge functions), you'll need to install
the `@langchain/google-vertexai-web` package.

Then, you'll need to add your service account credentials directly as a `GOOGLE_VERTEX_AI_WEB_CREDENTIALS` environment variable:

```
GOOGLE_VERTEX_AI_WEB_CREDENTIALS={"type":"service_account","project_id":"YOUR_PROJECT-12345",...}
```

You can also pass your credentials directly in code like this:

```typescript
import { VertexAI } from "@langchain/google-vertexai";
// Or uncomment this line if you're using the web version:
// import { VertexAI } from "@langchain/google-vertexai-web";

const model = new VertexAI({
  authOptions: {
    credentials: {"type":"service_account","project_id":"YOUR_PROJECT-12345",...},
  },
});
```

If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### Installation

The LangChain VertexAI integration lives in the `@langchain/google-vertexai` package:

<CodeGroup>
```bash npm
npm install @langchain/google-vertexai @langchain/core
```
```bash yarn
yarn add @langchain/google-vertexai @langchain/core
```
```bash pnpm
pnpm add @langchain/google-vertexai @langchain/core
```
</CodeGroup>

or for web environments:

<CodeGroup>
```bash npm
npm install @langchain/google-vertexai-web @langchain/core
```
```bash yarn
yarn add @langchain/google-vertexai-web @langchain/core
```
```bash pnpm
pnpm add @langchain/google-vertexai-web @langchain/core
```
</CodeGroup>

## Instantiation

Now we can instantiate our model object and generate chat completions:

```typescript
import { VertexAI } from "@langchain/google-vertexai-web"

const llm = new VertexAI({
  model: "gemini-pro",
  temperature: 0,
  maxRetries: 2,
  // other params...
})
```

## Invocation

```typescript
const inputText = "VertexAI is an AI company that "

const completion = await llm.invoke(inputText)
completion
```

```txt
offers a wide range of cloud computing services and artificial intelligence solutions to businesses and developers worldwide.
```

## API reference

For detailed documentation of all VertexAI features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_google_vertexai.VertexAI.html).
