---
title: HuggingFaceInference
---

Here's an example of calling a HugggingFaceInference model as an LLM:

```bash npm
npm install @langchain/community @langchain/core @huggingface/inference@4
```

<Tip>
We're unifying model params across all packages. We now suggest using `model` instead of `modelName`, and `apiKey` for API keys.
</Tip>

```typescript
import { HuggingFaceInference } from "@langchain/community/llms/hf";

const model = new HuggingFaceInference({
  model: "gpt2",
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.HUGGINGFACEHUB_API_KEY
});
const res = await model.invoke("1 + 1 =");
console.log({ res });
```

## Related


- [Models guide](/oss/langchain/models)
