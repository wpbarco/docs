{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Customer Support with Handoffs\n",
    "\n",
    "## Overview\n",
    "\n",
    "The **handoffs pattern** is a multi-agent architecture where agents pass control to each other through state transitions. This tutorial demonstrates how to build an online customer support system where different \"agents\" (really, different configurations of a single agent) handle specific stages of the support workflow.\n",
    "\n",
    "In this tutorial, you'll build a support bot that:\n",
    "- Collects warranty information before proceeding\n",
    "- Classifies issues as hardware or software\n",
    "- Provides solutions or escalates to human support\n",
    "- Maintains conversation state across multiple turns\n",
    "\n",
    "Unlike the supervisor pattern where subagents are called as tools, handoffs create a **state machine** where the active agent changes based on workflow progress. The key insight is that each \"agent\" is just a different configuration (system prompt + tools) of the same underlying agent, selected dynamically based on state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Installation\n",
    "\n",
    "First, install the required package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith Setup\n",
    "\n",
    "Set up LangSmith to inspect what is happening inside your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Chat Model\n",
    "\n",
    "Select a chat model to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chat_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m init_chat_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manthropic:claude-3-5-sonnet-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chat_models'"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Custom State\n",
    "\n",
    "First, define a custom state schema that tracks which agent is currently active:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "from typing_extensions import NotRequired\n",
    "from typing import Literal\n",
    "\n",
    "# Define the possible agent types\n",
    "AgentType = Literal[\"warranty_collector\", \"issue_classifier\", \"resolution_specialist\"]\n",
    "\n",
    "class SupportState(AgentState):\n",
    "    \"\"\"State for customer support workflow with handoffs.\"\"\"\n",
    "    active_agent: NotRequired[AgentType]\n",
    "    warranty_status: NotRequired[Literal[\"in_warranty\", \"out_of_warranty\", \"unknown\"]]\n",
    "    issue_type: NotRequired[Literal[\"hardware\", \"software\", \"unknown\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `active_agent` field is the core of the handoffs pattern - it determines which agent configuration is loaded on each turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Agent Configurations\n",
    "\n",
    "Create a dataclass to hold agent configurations. Each configuration specifies the system prompt and available tools for that agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    \"\"\"Configuration for a specific agent in the handoff workflow.\"\"\"\n",
    "    name: AgentType\n",
    "    system_prompt: str\n",
    "    tools: List[BaseTool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Handoff and Workflow Tools\n",
    "\n",
    "Create tools that update the workflow state. These tools allow agents to record information and transition to the next agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "\n",
    "@tool\n",
    "def record_warranty_status(\n",
    "    status: Literal[\"in_warranty\", \"out_of_warranty\"],\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> Command:\n",
    "    \"\"\"Record the customer's warranty status and transition to issue classification.\"\"\"\n",
    "    return Command(update={\n",
    "        \"warranty_status\": status,\n",
    "        \"active_agent\": \"issue_classifier\"\n",
    "    })\n",
    "\n",
    "@tool\n",
    "def record_issue_type(\n",
    "    issue_type: Literal[\"hardware\", \"software\"],\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> Command:\n",
    "    \"\"\"Record the type of issue and transition to resolution specialist.\"\"\"\n",
    "    return Command(update={\n",
    "        \"issue_type\": issue_type,\n",
    "        \"active_agent\": \"resolution_specialist\"\n",
    "    })\n",
    "\n",
    "@tool\n",
    "def escalate_to_human(\n",
    "    reason: str,\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> str:\n",
    "    \"\"\"Escalate the case to a human support specialist.\"\"\"\n",
    "    # In a real system, this would create a ticket, notify staff, etc.\n",
    "    return f\"Escalating to human support. Reason: {reason}\"\n",
    "\n",
    "@tool\n",
    "def provide_solution(\n",
    "    solution: str,\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> str:\n",
    "    \"\"\"Provide a solution to the customer's issue.\"\"\"\n",
    "    return f\"Solution provided: {solution}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Agent Configurations\n",
    "\n",
    "Now define the specific configurations for each agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_CONFIGS = {\n",
    "    \"warranty_collector\": AgentConfig(\n",
    "        name=\"warranty_collector\",\n",
    "        system_prompt=\"\"\"You are a warranty verification specialist.\n",
    "\n",
    "Your task:\n",
    "1. Greet the customer warmly\n",
    "2. Ask if their device is under warranty\n",
    "3. Use record_warranty_status to record their response and move to the next step\n",
    "\n",
    "Be conversational and friendly. Don't ask multiple questions at once.\"\"\",\n",
    "        tools=[record_warranty_status]\n",
    "    ),\n",
    "\n",
    "    \"issue_classifier\": AgentConfig(\n",
    "        name=\"issue_classifier\",\n",
    "        system_prompt=\"\"\"You are an issue classification specialist.\n",
    "\n",
    "Your task:\n",
    "1. Ask the customer to describe their issue\n",
    "2. Determine if it's a hardware issue (physical damage, broken parts) or software issue (app crashes, performance)\n",
    "3. Use record_issue_type to record the classification and move to the next step\n",
    "\n",
    "If unclear, ask clarifying questions before classifying.\"\"\",\n",
    "        tools=[record_issue_type]\n",
    "    ),\n",
    "\n",
    "    \"resolution_specialist\": AgentConfig(\n",
    "        name=\"resolution_specialist\",\n",
    "        system_prompt=\"\"\"You are a technical resolution specialist.\n",
    "\n",
    "Context available to you:\n",
    "- Warranty status: {warranty_status}\n",
    "- Issue type: {issue_type}\n",
    "\n",
    "Your task:\n",
    "1. For SOFTWARE issues: provide troubleshooting steps using provide_solution\n",
    "2. For HARDWARE issues:\n",
    "   - If IN WARRANTY: explain warranty repair process using provide_solution\n",
    "   - If OUT OF WARRANTY: escalate_to_human for paid repair options\n",
    "\n",
    "Be specific and helpful in your solutions.\"\"\",\n",
    "        tools=[provide_solution, escalate_to_human]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the resolution specialist's prompt references state variables - we'll inject these dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Dynamic Configuration Middleware\n",
    "\n",
    "Create middleware that reads the `active_agent` state and configures the agent accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse\nfrom langchain_core.messages import SystemMessage, HumanMessage, AIMessage\nfrom typing import Callable\n\nclass HandoffMiddleware(AgentMiddleware[SupportState]):\n    \"\"\"Middleware that dynamically configures the agent based on active_agent state.\n    \n    This middleware manages agent-specific message histories to ensure each agent\n    only sees relevant context, preventing unbounded history growth and confusion.\n    \"\"\"\n\n    state_schema = SupportState\n\n    def __init__(self, agent_configs: dict[AgentType, AgentConfig]):\n        super().__init__()\n        self.agent_configs = agent_configs\n\n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse]\n    ) -> ModelResponse:\n        \"\"\"Configure system prompt, tools, and message history based on active_agent.\"\"\"\n\n        # Get the current active agent from state (default to warranty_collector)\n        active_agent = request.state.get(\"active_agent\", \"warranty_collector\")\n        config = self.agent_configs[active_agent]\n\n        # Build context summary from state (what previous agents learned)\n        context = self._build_context_summary(request.state)\n        \n        # Format the system prompt with current state values\n        system_prompt = config.system_prompt.format(\n            warranty_status=request.state.get(\"warranty_status\", \"unknown\"),\n            issue_type=request.state.get(\"issue_type\", \"unknown\")\n        )\n        \n        # Inject context summary into system prompt\n        if context:\n            system_prompt += f\"\\n\\n{context}\"\n\n        # Get only recent, relevant messages for this agent\n        relevant_messages = self._get_recent_messages(request.messages, max_turns=2)\n        \n        # Construct valid message sequence: System message, then conversation\n        messages = [SystemMessage(content=system_prompt)] + relevant_messages\n\n        # Update request with new configuration\n        request.messages = messages\n        request.tools = config.tools\n\n        return handler(request)\n    \n    def _build_context_summary(self, state: dict) -> str:\n        \"\"\"Build a summary of what previous agents learned from state.\n        \n        This allows each agent to have a clean message history while still\n        having access to structured information gathered by previous agents.\n        \"\"\"\n        parts = []\n        \n        if state.get(\"warranty_status\") and state[\"warranty_status\"] != \"unknown\":\n            parts.append(f\"The customer's warranty status has been confirmed as: {state['warranty_status']}.\")\n        \n        if state.get(\"issue_type\") and state[\"issue_type\"] != \"unknown\":\n            parts.append(f\"The issue has been classified as: {state['issue_type']}.\")\n        \n        return \" \".join(parts) if parts else \"\"\n    \n    def _get_recent_messages(self, messages: list, max_turns: int = 2) -> list:\n        \"\"\"Get last N conversation turns, ensuring valid message sequence.\n        \n        A turn consists of: user message + AI response (+ optional tool messages).\n        This prevents message history from growing unbounded and ensures each\n        agent only sees its relevant context.\n        \n        Args:\n            messages: Full message history\n            max_turns: Maximum number of conversation turns to retain\n            \n        Returns:\n            List of recent messages forming complete, valid turns\n        \"\"\"\n        if not messages:\n            return []\n        \n        # Work backwards to collect complete turns\n        turns = []\n        current_turn = []\n        \n        for msg in reversed(messages):\n            if isinstance(msg, SystemMessage):\n                continue  # Skip old system messages (we inject our own)\n            \n            current_turn.insert(0, msg)\n            \n            # A turn starts with a user message\n            if isinstance(msg, HumanMessage):\n                turns.insert(0, current_turn)\n                current_turn = []\n                \n                if len(turns) >= max_turns:\n                    break\n        \n        # Flatten turns into message list\n        result = []\n        for turn in turns:\n            result.extend(turn)\n        \n        # Ensure we start with a user message for valid history\n        # (Most LLM providers require this pattern)\n        while result and not isinstance(result[0], HumanMessage):\n            result.pop(0)\n        \n        return result"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This middleware:\n1. Reads `active_agent` from state to determine which agent configuration to use\n2. Looks up the corresponding configuration (system prompt + tools)\n3. **Builds a context summary** from state that captures what previous agents learned\n4. Injects the system prompt with both state values AND the context summary\n5. **Filters message history** to only include recent turns (prevents unbounded growth)\n6. Ensures valid message sequences (system → user → AI → tool alternation)\n\n### Key Innovation: Separation of State and Messages\n\nThe middleware solves a critical problem with multi-agent handoffs:\n\n**Problem**: If all agents see the full message history, it grows unbounded and agents get confused by other agents' conversations.\n\n**Solution**: \n- **State dict** holds structured data (warranty status, issue type) - this is the cross-agent memory\n- **Message history** is agent-scoped and bounded - each agent only sees its recent conversation\n- **System message** injects context summaries from state - agents know what happened without seeing full history\n\nThis means:\n- The warranty_collector doesn't see issue_classifier's messages\n- The resolution_specialist doesn't see warranty_collector's messages\n- BUT each agent knows what was learned via state summaries in their system prompt"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create the Agent\n",
    "\n",
    "Now create the agent with the handoff middleware and a checkpointer for state persistence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Collect all tools from all configurations\n",
    "all_tools = []\n",
    "for config in AGENT_CONFIGS.values():\n",
    "    all_tools.extend(config.tools)\n",
    "\n",
    "# Create the agent with middleware\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=all_tools,\n",
    "    state_schema=SupportState,\n",
    "    middleware=[HandoffMiddleware(AGENT_CONFIGS)],\n",
    "    checkpointer=InMemorySaver()  # Required for state persistence across turns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why a checkpointer?** The checkpointer maintains state across conversation turns. Without it, the `active_agent` state would be lost between user messages, breaking the handoff flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test the Workflow\n",
    "\n",
    "Test the complete handoff workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configuration for this conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"support-001\"}}\n",
    "\n",
    "# Initial message - starts with warranty_collector\n",
    "print(\"=== Turn 1: Warranty Collection ===\")\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(\"Hi, my phone screen is cracked\")]\n",
    "    },\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User responds about warranty\n",
    "print(\"\\n=== Turn 2: User responds about warranty ===\")\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(\"Yes, it's still under warranty\")]\n",
    "    },\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(f\"Active agent: {result.get('active_agent')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User describes the issue\n",
    "print(\"\\n=== Turn 3: Issue classification ===\")\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(\"The screen is physically cracked, it happened when I dropped it\")]\n",
    "    },\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(f\"Active agent: {result.get('active_agent')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution\n",
    "print(\"\\n=== Turn 4: Resolution ===\")\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(\"What should I do?\")]\n",
    "    },\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected flow:\n",
    "1. **Warranty Collector**: Asks about warranty status\n",
    "2. **Issue Classifier**: Asks about the problem, determines it's hardware\n",
    "3. **Resolution Specialist**: Provides warranty repair instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Turn 3: After issue classified\nTool call: `record_issue_type(\"hardware\")` returns:\n```python\nCommand(update={\n    \"issue_type\": \"hardware\",\n    \"active_agent\": \"resolution_specialist\"  # State transition!\n})\n```\n\nNext turn, middleware configures:\n- System prompt: Resolution specialist instructions (with state context)\n- Tools: `[provide_solution, escalate_to_human]`\n\n## Message History Management\n\nA critical aspect of the handoffs pattern is managing what each agent sees. The middleware implements **message history scoping** to solve several problems:\n\n### The Problem\n\nWithout message history management:\n```python\n# Full conversation after 3 agent transitions:\n[\n    HumanMessage(\"Hi, my phone screen is cracked\"),\n    AIMessage(\"Is your device under warranty?\"),  # warranty_collector\n    HumanMessage(\"Yes, it's still under warranty\"),\n    AIMessage(\"Tool: record_warranty_status\"),     # warranty_collector\n    ToolMessage(\"Recorded warranty status\"),\n    AIMessage(\"Can you describe the issue?\"),      # issue_classifier\n    HumanMessage(\"The screen is physically cracked\"),\n    AIMessage(\"Tool: record_issue_type\"),          # issue_classifier\n    ToolMessage(\"Recorded issue type\"),\n    AIMessage(\"I can help with warranty repair\"),  # resolution_specialist\n]\n```\n\n**Problems**:\n- ❌ Message history grows unbounded (9+ messages after just 3 turns)\n- ❌ Resolution specialist sees warranty_collector's conversation\n- ❌ Agents can get confused by other agents' messages\n- ❌ No way to give an agent just its own conversation context\n\n### The Solution: Message Scoping + State Summaries\n\nThe middleware's `_get_recent_messages()` method keeps only the last 2 conversation turns:\n\n```python\n# What resolution_specialist actually sees:\n[\n    SystemMessage(\"\"\"You are a technical resolution specialist.\n    \n    Context:\n    - Warranty status: in_warranty\n    - Issue type: hardware\n    \n    The customer's warranty status has been confirmed as: in_warranty.\n    The issue has been classified as: hardware.\n    \"\"\"),\n    HumanMessage(\"The screen is physically cracked\"),\n    AIMessage(\"Tool: record_issue_type\"),\n    ToolMessage(\"Recorded issue type\"),\n    HumanMessage(\"What should I do?\"),  # Current user message\n]\n```\n\n**Benefits**:\n- ✅ Bounded message history (only 2-3 recent turns)\n- ✅ Agent sees only its own conversation\n- ✅ Context from previous agents available via system message\n- ✅ State dict provides structured cross-agent memory\n- ✅ Valid message sequences maintained (user/AI/tool alternation)\n\n### Valid Message Sequences\n\nThe middleware ensures message histories always follow LLM provider requirements:\n\n**Valid patterns**:\n```\nSystem → User → AI\nSystem → User → AI (with tool calls) → Tool → AI → User\n```\n\n**Invalid patterns** (prevented by middleware):\n```\nAI → AI  # Two consecutive AI messages\nTool → User  # Tool message without preceding AI tool call\nAI (with tool calls) → User  # Missing tool response\n```\n\nThe `_get_recent_messages()` method specifically:\n1. Collects complete \"turns\" (user message + AI response + any tool messages)\n2. Removes orphaned tool messages without their AI message\n3. Ensures the sequence always starts with a user message\n\n### Debugging: Inspecting Agent Views\n\nYou can add logging to see what each agent actually sees:"
  },
  {
   "cell_type": "markdown",
   "source": "The logging shows:\n- Which agent is active\n- Exactly what messages that agent sees (after filtering)\n- The current state values\n- What tools are available to that agent\n\nThis makes it easy to verify that:\n1. Each agent only sees its recent conversation turns\n2. Context from previous agents appears in the system message\n3. Message sequences are valid\n4. State is correctly passed between agents",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Enhanced middleware with logging for debugging\nclass HandoffMiddlewareWithLogging(HandoffMiddleware):\n    \"\"\"Extended middleware that logs what each agent sees.\"\"\"\n    \n    def wrap_model_call(\n        self,\n        request: ModelRequest,\n        handler: Callable[[ModelRequest], ModelResponse]\n    ) -> ModelResponse:\n        active_agent = request.state.get(\"active_agent\", \"warranty_collector\")\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"AGENT: {active_agent}\")\n        print(f\"{'='*60}\")\n        \n        # Call parent implementation\n        response = super().wrap_model_call(request, handler)\n        \n        # Log what the agent saw\n        print(f\"\\nMessages sent to {active_agent}:\")\n        for i, msg in enumerate(request.messages):\n            msg_type = type(msg).__name__\n            content_preview = str(msg.content)[:100]\n            print(f\"  {i}. {msg_type}: {content_preview}...\")\n        \n        print(f\"\\nState: {dict(request.state)}\")\n        print(f\"Tools available: {[t.name for t in request.tools]}\")\n        \n        return response\n\n# Recreate agent with logging middleware\nagent_debug = create_agent(\n    model,\n    tools=all_tools,\n    state_schema=SupportState,\n    middleware=[HandoffMiddlewareWithLogging(AGENT_CONFIGS)],\n    checkpointer=InMemorySaver()\n)\n\n# Test with logging\nconfig_debug = {\"configurable\": {\"thread_id\": \"debug-001\"}}\n\nprint(\"Turn 1: Initial message\")\nresult = agent_debug.invoke(\n    {\"messages\": [HumanMessage(\"My device has an issue\")]},\n    config_debug\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Adding Flexibility - Going Back\n",
    "\n",
    "A key UX requirement is allowing users to correct mistakes. Add \"go back\" tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def go_back_to_warranty(\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> Command:\n",
    "    \"\"\"Go back to warranty verification step.\"\"\"\n",
    "    return Command(update={\n",
    "        \"active_agent\": \"warranty_collector\",\n",
    "        \"warranty_status\": \"unknown\"  # Reset warranty status\n",
    "    })\n",
    "\n",
    "@tool\n",
    "def go_back_to_classification(\n",
    "    runtime: ToolRuntime[None, SupportState]\n",
    ") -> Command:\n",
    "    \"\"\"Go back to issue classification step.\"\"\"\n",
    "    return Command(update={\n",
    "        \"active_agent\": \"issue_classifier\",\n",
    "        \"issue_type\": \"unknown\"  # Reset issue type\n",
    "    })\n",
    "\n",
    "# Add these tools to resolution_specialist configuration\n",
    "AGENT_CONFIGS[\"resolution_specialist\"].tools.extend([\n",
    "    go_back_to_warranty,\n",
    "    go_back_to_classification\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the resolution specialist's prompt to include navigation instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_CONFIGS[\"resolution_specialist\"].system_prompt = \"\"\"You are a technical resolution specialist.\n",
    "\n",
    "Context:\n",
    "- Warranty status: {warranty_status}\n",
    "- Issue type: {issue_type}\n",
    "\n",
    "Your task:\n",
    "1. For SOFTWARE issues: provide troubleshooting steps using provide_solution\n",
    "2. For HARDWARE issues:\n",
    "   - If IN WARRANTY: explain warranty repair process\n",
    "   - If OUT OF WARRANTY: escalate_to_human for paid repair options\n",
    "\n",
    "If the customer indicates any information was wrong, use:\n",
    "- go_back_to_warranty to correct warranty status\n",
    "- go_back_to_classification to correct issue type\n",
    "\n",
    "Be specific and helpful in your solutions.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recreate the agent with the updated configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools from all configurations (including new go_back tools)\n",
    "all_tools = []\n",
    "for config in AGENT_CONFIGS.values():\n",
    "    all_tools.extend(config.tools)\n",
    "\n",
    "# Recreate agent with updated tools\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=all_tools,\n",
    "    state_schema=SupportState,\n",
    "    middleware=[HandoffMiddleware(AGENT_CONFIGS)],\n",
    "    checkpointer=InMemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the correction flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation and test going back\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(\"Actually, I made a mistake - my device is out of warranty\")]\n",
    "    },\n",
    "    config\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(f\"Active agent: {result.get('active_agent')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\nThe handoffs pattern demonstrates several important concepts:\n\n1. **State machines**: The `active_agent` field creates a state machine where each state has different behavior (prompts + tools).\n\n2. **Dynamic configuration**: Middleware reads state and configures the agent on-the-fly, eliminating the need for separate agent instances.\n\n3. **Message history scoping**: Each agent sees only its recent conversation, preventing unbounded growth and confusion. The middleware:\n   - Keeps only the last 2-3 conversation turns for each agent\n   - Injects context summaries from state into system messages\n   - Ensures valid message sequences (user/AI/tool alternation)\n\n4. **State as cross-agent memory**: The state dict (not message history) is the primary mechanism for sharing information between agents:\n   - Structured data (warranty_status, issue_type) persists across handoffs\n   - System messages inject state summaries for context\n   - Messages remain agent-scoped and ephemeral\n\n5. **State persistence**: A checkpointer maintains state across conversation turns, enabling the handoff mechanism.\n\n6. **Sequential workflows**: Perfect for collecting information in a specific order (warranty → classification → resolution).\n\n7. **Flexibility**: Tools can transition forward OR backward, allowing users to correct mistakes.\n\n### When to use handoffs vs supervisor pattern\n\nUse **handoffs** when:\n- Agents need direct conversation with users\n- Workflow requires sequential information collection\n- State transitions depend on user responses\n- Each agent needs its own conversation context\n\nUse **supervisor** when:\n- Sub-agents don't need to converse with users\n- You want centralized orchestration\n- Sub-agents are truly independent specialists\n\nYou can also mix both patterns!\n\n### Message History Management Strategy\n\nThe key insight: **Separate message history from cross-agent memory**\n\n- **Message history** = Agent-scoped, bounded, ephemeral conversation\n- **State dict** = Cross-agent, persistent, structured data\n- **System messages** = Bridge between state and agent context\n\nThis separation ensures:\n- Agents aren't confused by other agents' conversations\n- Message histories don't grow unbounded\n- Valid message sequences are maintained\n- Agents still have full context via state summaries"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}