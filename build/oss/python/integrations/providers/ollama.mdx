---
title: Ollama
---

All LangChain integrations with [Ollama](https://ollama.com/).

Ollama allows you to run open-source models (like [`gpt-oss`](https://ollama.com/library/gpt-oss)) locally.

For a complete list of supported models and variants, see the [Ollama model library](https://ollama.ai/library).

## Model interfaces

<Columns cols={2}>
    <Card title="ChatOllama" href="/oss/python/integrations/chat/ollama" cta="Get started" icon="message" arrow>
        Ollama chat models.
    </Card>
    <Card title="OllamaLLM" href="/oss/python/integrations/llms/ollama" cta="Get started" icon="i-cursor" arrow>
        (Legacy) Ollama text completion models.
    </Card>
    <Card title="OllamaEmbeddings" href="/oss/python/integrations/text_embedding/ollama" cta="Get started" icon="microsoft" arrow>
        Ollama embedding models.
    </Card>
</Columns>

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/ollama.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    Connect these docs to Claude, VSCode, and more via MCP for    real-time answers. [See how](/use-these-docs)
</Tip>
