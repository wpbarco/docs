---
title: Snowflake
---

> [Snowflake](https://www.snowflake.com/) is a cloud-based data-warehousing platform
> that allows you to store and query large amounts of data.

This page covers how to use the `Snowflake` ecosystem within `LangChain`.

## Embedding models

Snowflake offers their open-weight `arctic` line of embedding models for free
on [Hugging Face](https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5). The most recent model, snowflake-arctic-embed-m-v1.5 feature [matryoshka embedding](https://arxiv.org/abs/2205.13147) which allows for effective vector truncation.
You can use these models via the
[HuggingFaceEmbeddings](/oss/python/integrations/text_embedding/huggingfacehub) connector:

<CodeGroup>
```bash pip
pip install langchain-community sentence-transformers
```

```bash uv
uv add langchain-community sentence-transformers
```
</CodeGroup>

```python
from langchain_huggingface import HuggingFaceEmbeddings

model = HuggingFaceEmbeddings(model_name="snowflake/arctic-embed-m-v1.5")
```

## Document loader

You can use the [`SnowflakeLoader`](/oss/python/integrations/document_loaders/snowflake)
to load data from Snowflake:

```python
from langchain_community.document_loaders import SnowflakeLoader
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/snowflake.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    Connect these docs to Claude, VSCode, and more via MCP for    real-time answers. [See how](/use-these-docs)
</Tip>
