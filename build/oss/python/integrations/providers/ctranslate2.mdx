---
title: CTranslate2
---

>[CTranslate2](https://opennmt.net/CTranslate2/quickstart.html) is a C++ and Python library
> for efficient inference with Transformer models.
>
>The project implements a custom runtime that applies many performance optimization
> techniques such as weights quantization, layers fusion, batch reordering, etc.,
> to accelerate and reduce the memory usage of Transformer models on CPU and GPU.
>
>A full list of features and supported models is included in the
> [projectâ€™s repository](https://opennmt.net/CTranslate2/guides/transformers.html).
> To start, please check out the official [quickstart guide](https://opennmt.net/CTranslate2/quickstart.html).


## Installation and Setup

Install the Python package:

<CodeGroup>
```bash pip
pip install ctranslate2
```

```bash uv
uv add ctranslate2
```
</CodeGroup>


## LLMs

See a [usage example](/oss/python/integrations/llms/ctranslate2).

```python
from langchain_community.llms import CTranslate2
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/ctranslate2.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    Connect these docs to Claude, VSCode, and more via MCP for    real-time answers. [See how](/use-these-docs)
</Tip>
