---
title: Aleph Alpha
---

[The Luminous series](https://docs.aleph-alpha.com/docs/category/luminous/) is a family of large language models.

This example goes over how to use LangChain to interact with Aleph Alpha models

```python
# Installing the langchain package needed to use the integration
pip install -qU langchain-community
```

```python
# Install the package
pip install -qU  aleph-alpha-client
```

```python
# create a new token: https://docs.aleph-alpha.com/docs/account/#create-a-new-token

from getpass import getpass

ALEPH_ALPHA_API_KEY = getpass()
```

```output
········
```

```python
from langchain_community.llms import AlephAlpha
from langchain_core.prompts import PromptTemplate
```

```python
template = """Q: {question}

A:"""

prompt = PromptTemplate.from_template(template)
```

```python
llm = AlephAlpha(
    model="luminous-extended",
    maximum_tokens=20,
    stop_sequences=["Q:"],
    aleph_alpha_api_key=ALEPH_ALPHA_API_KEY,
)
```

```python
llm_chain = prompt | llm
```

```python
question = "What is AI?"

llm_chain.invoke({"question": question})
```

```output
' Artificial Intelligence is the simulation of human intelligence processes by machines.\n\n'
```

```python

```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/llms/aleph_alpha.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    Connect these docs to Claude, VSCode, and more via MCP for    real-time answers. [See how](/use-these-docs)
</Tip>
