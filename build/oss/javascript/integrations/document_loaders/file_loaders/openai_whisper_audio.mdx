---
title: Open AI Whisper Audio
---

<Tip>
**Compatibility**

Only available on Node.js.
</Tip>

This covers how to load document objects from an audio file using the [Open AI Whisper](https://platform.openai.com/docs/guides/speech-to-text) API.

## Setup

To run this loader you will need to create an account on the Open AI and obtain an auth key from the https://platform.openai.com/account page.

## Usage

Once auth key is configured, you can use the loader to create transcriptions and then convert them into a Document.

```typescript
import { OpenAIWhisperAudio } from "@langchain/community/document_loaders/fs/openai_whisper_audio";

const filePath = "./src/document_loaders/example_data/test.mp3";

const loader = new OpenAIWhisperAudio(filePath, {
  transcriptionCreateParams: {
    language: "en",
  },
});

const docs = await loader.load();

console.log(docs);
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/document_loaders/file_loaders/openai_whisper_audio.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    Connect these docs to Claude, VSCode, and more via MCP for    real-time answers. [See how](/use-these-docs)
</Tip>
