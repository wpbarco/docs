---
title: Configuration options
---

Deep Agents provides a number of configuration options to customize the agent's behavior and capabilities:

- **Tools** (required): The tools that the agent and any subagents will have access to.
- **Instructions** (required): Custom instructions that serve as part of the agent's prompt. This supplements the built-in system prompt.
- **Sub-agents**: Specialized subagents for specific tasks.
- **Model**: The model to use for the agent.

## Tools

Required. A list of tools that the agent and any subagents will have access to.

## Instructions

Required. Custom instructions that serve as part of the agent's prompt. This supplements the built-in system prompt.

## Sub-agents

Define specialized subagents for specific tasks:

<CodeGroup>

```python Python
subagents = [{
    "name": "research-agent",
    "description": "Used to research more in depth questions",
    "prompt": sub_research_prompt,
    "tools": ["internet_search"]  # Optional: defaults to all tools
}]

agent = create_deep_agent(
    tools=tools,
    instructions=prompt,
    subagents=subagents
)
```

```typescript JavaScript
interface SubAgent {
  name: string;
  description: string;
  prompt: string;
  tools?: string[];
}

const researchSubAgent: SubAgent = {
  name: "research-agent",
  description: "Used to research more in depth questions",
  prompt: subResearchPrompt,
};

const agent = createDeepAgent({
  tools,
  instructions: prompt,
  subagents: [researchSubAgent]
});
```

</CodeGroup>

## Model

Both the Python and JavaScript implementations default to `"claude-sonnet-4-20250514"` but support custom models:

<CodeGroup>

```python Python
from langchain_openai import ChatOpenAI

custom_model = ChatOpenAI(model="gpt-4")
agent = create_deep_agent(
    tools=tools,
    instructions=instructions,
    model=custom_model
)
```

```typescript JavaScript
import { ChatOpenAI } from "@langchain/openai";

const customModel = new ChatOpenAI({ model: "gpt-4" });
const agent = createDeepAgent({
  tools,
  instructions,
  model: customModel
});
```

</CodeGroup>

### Custom models

<Note>

Custom models are only supported in the Python implementation.

</Note>

By default, `deepagents` uses `"claude-sonnet-4-20250514"`. You can customize this by passing any [LangChain model object](https://python.langchain.com/docs/integrations/chat/).

For example, use OpenAI's `gpt-oss` model via Ollama:

```python
# pip install langchain langchain-ollama

from deepagents import create_deep_agent

# ... existing agent definitions ...

model = init_chat_model(
    model="ollama:gpt-oss:20b",
)
agent = create_deep_agent(
    tools=tools,
    instructions=instructions,
    model=model,
    ...
)
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/labs/deep-agents/configuration-options.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    Connect these docs to Claude, VSCode, and more via MCP for    real-time answers. [See how](/use-these-docs)
</Tip>
